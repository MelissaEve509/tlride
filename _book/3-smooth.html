<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A Ride in Targeted Learning Territory</title>
  <meta name="description" content="To do…">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="A Ride in Targeted Learning Territory" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="cover.jpg" />
  <meta property="og:description" content="To do…" />
  <meta name="github-repo" content="achambaz/tlride" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Ride in Targeted Learning Territory" />
  
  <meta name="twitter:description" content="To do…" />
  <meta name="twitter:image" content="cover.jpg" />

<meta name="author" content="David Benkeser (Emory University)">
<meta name="author" content="Antoine Chambaz (Université Paris Descartes)">


<meta name="date" content="2018-10-18">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="favicon.png" type="image/x-icon">
<link rel="prev" href="2-parameter.html">
<link rel="next" href="4-double-robustness.html">
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  CommonHTML: {
    scale: 90,
    linebreaks: {
      automatic: true
    }
  },
  SVG: {
    linebreaks: {
      automatic: true
    }
  }, 
  displayAlign: "left"
  });
</script>
<script type="text/javascript"
	src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script><!-- see also '_output.yaml'
src="https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"
src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML" 
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
-->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="tlride.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">TLRIDE</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="1-a-ride.html"><a href="1-a-ride.html"><i class="fa fa-check"></i><b>1</b> A ride</a><ul>
<li class="chapter" data-level="1.1" data-path="1-a-ride.html"><a href="1-a-ride.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-a-ride.html"><a href="1-a-ride.html#causal-story"><i class="fa fa-check"></i><b>1.1.1</b> A causal story</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-a-ride.html"><a href="1-a-ride.html#tlrider-package"><i class="fa fa-check"></i><b>1.1.2</b> The <code>tlrider</code> package</a></li>
<li class="chapter" data-level="1.1.3" data-path="1-a-ride.html"><a href="1-a-ride.html#discuss"><i class="fa fa-check"></i><b>1.1.3</b> What we will discuss</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-a-ride.html"><a href="1-a-ride.html#simulation-study"><i class="fa fa-check"></i><b>1.2</b> A simulation study</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-a-ride.html"><a href="1-a-ride.html#reproducible-experiment"><i class="fa fa-check"></i><b>1.2.1</b> Reproducible experiment as a law</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-a-ride.html"><a href="1-a-ride.html#synthetic-experiment"><i class="fa fa-check"></i><b>1.2.2</b> A synthetic reproducible experiment</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-a-ride.html"><a href="1-a-ride.html#revealing-experiment"><i class="fa fa-check"></i><b>1.2.3</b> Revealing <code>experiment</code></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-a-ride.html"><a href="1-a-ride.html#exo-visualization"><i class="fa fa-check"></i><b>1.3</b> ⚙ Visualization</a></li>
<li class="chapter" data-level="1.4" data-path="1-a-ride.html"><a href="1-a-ride.html#exo-make-own-experiment"><i class="fa fa-check"></i><b>1.4</b> ⚙ Make your own experiment</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-parameter.html"><a href="2-parameter.html"><i class="fa fa-check"></i><b>2</b> The parameter of interest</a><ul>
<li class="chapter" data-level="2.1" data-path="2-parameter.html"><a href="2-parameter.html#parameter-first-pass"><i class="fa fa-check"></i><b>2.1</b> The parameter of interest</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-parameter.html"><a href="2-parameter.html#definition"><i class="fa fa-check"></i><b>2.1.1</b> Definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-parameter.html"><a href="2-parameter.html#causal-interpretation"><i class="fa fa-check"></i><b>2.1.2</b> A causal interpretation</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-parameter.html"><a href="2-parameter.html#causal-computation"><i class="fa fa-check"></i><b>2.1.3</b> A causal computation</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-parameter.html"><a href="2-parameter.html#exo-alternative-parameter-first-pass"><i class="fa fa-check"></i><b>2.2</b> ⚙ An alternative parameter of interest</a></li>
<li class="chapter" data-level="2.3" data-path="2-parameter.html"><a href="2-parameter.html#parameter-second-pass"><i class="fa fa-check"></i><b>2.3</b> The statistical mapping of interest</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-parameter.html"><a href="2-parameter.html#opening"><i class="fa fa-check"></i><b>2.3.1</b> Opening discussion</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-parameter.html"><a href="2-parameter.html#parameter-mapping"><i class="fa fa-check"></i><b>2.3.2</b> The parameter as the value of a statistical mapping at the experiment</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-parameter.html"><a href="2-parameter.html#value-another-experiment"><i class="fa fa-check"></i><b>2.3.3</b> The value of the statistical mapping at another experiment</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-parameter.html"><a href="2-parameter.html#exo-alternative-parameter-second-pass"><i class="fa fa-check"></i><b>2.4</b> ⚙ Alternative statistical mapping</a></li>
<li class="chapter" data-level="2.5" data-path="2-parameter.html"><a href="2-parameter.html#parameter-third-pass"><i class="fa fa-check"></i><b>2.5</b> Representations</a><ul>
<li class="chapter" data-level="2.5.1" data-path="2-parameter.html"><a href="2-parameter.html#yet-another"><i class="fa fa-check"></i><b>2.5.1</b> Yet another representation</a></li>
<li class="chapter" data-level="2.5.2" data-path="2-parameter.html"><a href="2-parameter.html#rep-to-est"><i class="fa fa-check"></i><b>2.5.2</b> From representations to estimation strategies</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="2-parameter.html"><a href="2-parameter.html#exo-alternative-parameter-third-pass"><i class="fa fa-check"></i><b>2.6</b> ⚙ Alternative representation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-smooth.html"><a href="3-smooth.html"><i class="fa fa-check"></i><b>3</b> Smoothness</a><ul>
<li class="chapter" data-level="3.1" data-path="3-smooth.html"><a href="3-smooth.html#smooth-first-pass"><i class="fa fa-check"></i><b>3.1</b> Fluctuating smoothly</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-smooth.html"><a href="3-smooth.html#fluctuations"><i class="fa fa-check"></i><b>3.1.1</b> The <code>another_experiment</code> fluctuation</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-smooth.html"><a href="3-smooth.html#numerical-illus"><i class="fa fa-check"></i><b>3.1.2</b> Numerical illustration</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-smooth.html"><a href="3-smooth.html#exo-yet-another-experiment"><i class="fa fa-check"></i><b>3.2</b> ⚙ Yet another experiment</a></li>
<li class="chapter" data-level="3.3" data-path="3-smooth.html"><a href="3-smooth.html#smooth-second-pass"><i class="fa fa-check"></i><b>3.3</b> ☡  More on fluctuations and smoothness</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-smooth.html"><a href="3-smooth.html#fluctuations"><i class="fa fa-check"></i><b>3.3.1</b> Fluctuations</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-smooth.html"><a href="3-smooth.html#smoothness-and-gradients"><i class="fa fa-check"></i><b>3.3.2</b> Smoothness and gradients</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-smooth.html"><a href="3-smooth.html#Euclidean-perspective"><i class="fa fa-check"></i><b>3.3.3</b> A Euclidean perspective</a></li>
<li class="chapter" data-level="3.3.4" data-path="3-smooth.html"><a href="3-smooth.html#canonical-gradient"><i class="fa fa-check"></i><b>3.3.4</b> The canonical gradient</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-smooth.html"><a href="3-smooth.html#revisiting"><i class="fa fa-check"></i><b>3.4</b> A fresh look at <code>another_experiment</code></a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-smooth.html"><a href="3-smooth.html#deriving-the-efficient-influence-curve"><i class="fa fa-check"></i><b>3.4.1</b> Deriving the efficient influence curve</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-smooth.html"><a href="3-smooth.html#numerical-validation"><i class="fa fa-check"></i><b>3.4.2</b> Numerical validation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-smooth.html"><a href="3-smooth.html#influence-curves"><i class="fa fa-check"></i><b>3.5</b> ☡  Asymptotic linearity and statistical efficiency</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-smooth.html"><a href="3-smooth.html#asymptotic-linearity"><i class="fa fa-check"></i><b>3.5.1</b> Asymptotic linearity</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-smooth.html"><a href="3-smooth.html#influence-curves-and-gradients"><i class="fa fa-check"></i><b>3.5.2</b> Influence curves and gradients</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-smooth.html"><a href="3-smooth.html#asymptotic-efficiency"><i class="fa fa-check"></i><b>3.5.3</b> Asymptotic efficiency</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-smooth.html"><a href="3-smooth.html#exo-cramer-rao"><i class="fa fa-check"></i><b>3.6</b> ⚙ Cramér-Rao bounds</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-double-robustness.html"><a href="4-double-robustness.html"><i class="fa fa-check"></i><b>4</b> Double-robustness</a><ul>
<li class="chapter" data-level="4.1" data-path="4-double-robustness.html"><a href="4-double-robustness.html#linear-approximation"><i class="fa fa-check"></i><b>4.1</b> Linear approximations of parameters</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4-double-robustness.html"><a href="4-double-robustness.html#from-gradients-to-estimators"><i class="fa fa-check"></i><b>4.1.1</b> From gradients to estimators</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-double-robustness.html"><a href="4-double-robustness.html#another-Euclidean-perspective"><i class="fa fa-check"></i><b>4.1.2</b> A Euclidean perspective</a></li>
<li class="chapter" data-level="4.1.3" data-path="4-double-robustness.html"><a href="4-double-robustness.html#the-remainder-term"><i class="fa fa-check"></i><b>4.1.3</b> The remainder term</a></li>
<li class="chapter" data-level="4.1.4" data-path="4-double-robustness.html"><a href="4-double-robustness.html#expressing-the-remainder-term-as-a-function-of-the-relevant-features"><i class="fa fa-check"></i><b>4.1.4</b> Expressing the remainder term as a function of the relevant features</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-double-robustness.html"><a href="4-double-robustness.html#exo-remainder-term"><i class="fa fa-check"></i><b>4.2</b> ⚙ The remainder term</a></li>
<li class="chapter" data-level="4.3" data-path="4-double-robustness.html"><a href="4-double-robustness.html#def-double-robustness"><i class="fa fa-check"></i><b>4.3</b> ☡  Double-robustness</a><ul>
<li class="chapter" data-level="4.3.1" data-path="4-double-robustness.html"><a href="4-double-robustness.html#the-key-property"><i class="fa fa-check"></i><b>4.3.1</b> The key property</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-double-robustness.html"><a href="4-double-robustness.html#direct-consequence"><i class="fa fa-check"></i><b>4.3.2</b> Its direct consequence</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-double-robustness.html"><a href="4-double-robustness.html#exo-double-robustness"><i class="fa fa-check"></i><b>4.4</b> ⚙ Double-robustness</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-inference.html"><a href="5-inference.html"><i class="fa fa-check"></i><b>5</b> Inference</a><ul>
<li class="chapter" data-level="5.1" data-path="5-inference.html"><a href="5-inference.html#where-we-stand"><i class="fa fa-check"></i><b>5.1</b> Where we stand</a></li>
<li class="chapter" data-level="5.2" data-path="5-inference.html"><a href="5-inference.html#where-we-go"><i class="fa fa-check"></i><b>5.2</b> Where we go</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-simple-strategy.html"><a href="6-simple-strategy.html"><i class="fa fa-check"></i><b>6</b> A simple inference strategy</a><ul>
<li class="chapter" data-level="6.1" data-path="6-simple-strategy.html"><a href="6-simple-strategy.html#a-cautionary-detour"><i class="fa fa-check"></i><b>6.1</b> A cautionary detour</a></li>
<li class="chapter" data-level="6.2" data-path="6-simple-strategy.html"><a href="6-simple-strategy.html#delta-method"><i class="fa fa-check"></i><b>6.2</b> ⚙ Delta-method</a></li>
<li class="chapter" data-level="6.3" data-path="6-simple-strategy.html"><a href="6-simple-strategy.html#known-gbar-first-pass"><i class="fa fa-check"></i><b>6.3</b> IPTW estimator assuming the mechanism of action known</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-simple-strategy.html"><a href="6-simple-strategy.html#a-simple-substitution-estimator"><i class="fa fa-check"></i><b>6.3.1</b> A simple substitution estimator</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-simple-strategy.html"><a href="6-simple-strategy.html#elementary-statistical-properties"><i class="fa fa-check"></i><b>6.3.2</b> Elementary statistical properties</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-simple-strategy.html"><a href="6-simple-strategy.html#empirical-inves-IPTW"><i class="fa fa-check"></i><b>6.3.3</b> Empirical investigation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-nuisance.html"><a href="7-nuisance.html"><i class="fa fa-check"></i><b>7</b> Nuisance parameters</a><ul>
<li class="chapter" data-level="7.1" data-path="7-nuisance.html"><a href="7-nuisance.html#anatomy"><i class="fa fa-check"></i><b>7.1</b> Anatomy of an expression</a></li>
<li class="chapter" data-level="7.2" data-path="7-nuisance.html"><a href="7-nuisance.html#an-algorithmic-stance"><i class="fa fa-check"></i><b>7.2</b> An algorithmic stance</a></li>
<li class="chapter" data-level="7.3" data-path="7-nuisance.html"><a href="7-nuisance.html#nuisance-QW"><i class="fa fa-check"></i><b>7.3</b> <code>QW</code></a></li>
<li class="chapter" data-level="7.4" data-path="7-nuisance.html"><a href="7-nuisance.html#nuisance-Gbar"><i class="fa fa-check"></i><b>7.4</b> <code>Gbar</code></a><ul>
<li class="chapter" data-level="7.4.1" data-path="7-nuisance.html"><a href="7-nuisance.html#working-model-based-algorithms"><i class="fa fa-check"></i><b>7.4.1</b> Working model-based algorithms</a></li>
<li class="chapter" data-level="7.4.2" data-path="7-nuisance.html"><a href="7-nuisance.html#visualization"><i class="fa fa-check"></i><b>7.4.2</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="7-nuisance.html"><a href="7-nuisance.html#nuisance-Qbar-wm"><i class="fa fa-check"></i><b>7.5</b> ⚙ <code>Qbar</code>, working model-based algorithms</a></li>
<li class="chapter" data-level="7.6" data-path="7-nuisance.html"><a href="7-nuisance.html#nuisance-Qbar"><i class="fa fa-check"></i><b>7.6</b> <code>Qbar</code></a><ul>
<li class="chapter" data-level="7.6.1" data-path="7-nuisance.html"><a href="7-nuisance.html#qbar-machine-learning-based-algorithms"><i class="fa fa-check"></i><b>7.6.1</b> <code>Qbar</code>, machine learning-based algorithms</a></li>
<li class="chapter" data-level="7.6.2" data-path="7-nuisance.html"><a href="7-nuisance.html#Qbar-knn-algo"><i class="fa fa-check"></i><b>7.6.2</b> <code>Qbar</code>, kNN algorithm</a></li>
<li class="chapter" data-level="7.6.3" data-path="7-nuisance.html"><a href="7-nuisance.html#qbar-boosted-trees-algorithm"><i class="fa fa-check"></i><b>7.6.3</b> <code>Qbar</code>, boosted trees algorithm</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="7-nuisance.html"><a href="7-nuisance.html#nuisance-Qbar-ml-exo"><i class="fa fa-check"></i><b>7.7</b> ⚙ ☡  <code>Qbar</code>, machine learning-based algorithms</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html"><i class="fa fa-check"></i><b>8</b> Two “naive” plug-in inference strategies</a><ul>
<li class="chapter" data-level="8.1" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#why-naive"><i class="fa fa-check"></i><b>8.1</b> Why “naive”?</a></li>
<li class="chapter" data-level="8.2" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#known-gbar-second-pass"><i class="fa fa-check"></i><b>8.2</b> IPTW estimator</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#construction-and-computation"><i class="fa fa-check"></i><b>8.2.1</b> Construction and computation</a></li>
<li class="chapter" data-level="8.2.2" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#elementary-stat-prop-iptw"><i class="fa fa-check"></i><b>8.2.2</b> Elementary statistical properties</a></li>
<li class="chapter" data-level="8.2.3" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#empirical-inves-IPTW-bis"><i class="fa fa-check"></i><b>8.2.3</b> Empirical investigation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#exo-a-nice-title"><i class="fa fa-check"></i><b>8.3</b> ⚙ Investigating further the IPTW inference strategy</a></li>
<li class="chapter" data-level="8.4" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#Gcomp-estimator"><i class="fa fa-check"></i><b>8.4</b> G-computation estimator</a><ul>
<li class="chapter" data-level="8.4.1" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#construction-and-computation-1"><i class="fa fa-check"></i><b>8.4.1</b> Construction and computation</a></li>
<li class="chapter" data-level="8.4.2" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#elementary-statistical-properties-1"><i class="fa fa-check"></i><b>8.4.2</b> Elementary statistical properties</a></li>
<li class="chapter" data-level="8.4.3" data-path="8-two-naive-plug-in-inference-strategies.html"><a href="8-two-naive-plug-in-inference-strategies.html#empirical-inves-Gcomp"><i class="fa fa-check"></i><b>8.4.3</b> Empirical investigation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-work-in-progress.html"><a href="9-work-in-progress.html"><i class="fa fa-check"></i><b>9</b> Work in progress</a></li>
<li class="chapter" data-level="10" data-path="10-notation.html"><a href="10-notation.html"><i class="fa fa-check"></i><b>10</b> Notation</a></li>
<li class="chapter" data-level="11" data-path="11-proofs.html"><a href="11-proofs.html"><i class="fa fa-check"></i><b>11</b> Basic results and their proofs</a><ul>
<li class="chapter" data-level="11.1" data-path="11-proofs.html"><a href="11-proofs.html#npsem"><i class="fa fa-check"></i><b>11.1</b> NPSEM</a></li>
<li class="chapter" data-level="11.2" data-path="11-proofs.html"><a href="11-proofs.html#identification"><i class="fa fa-check"></i><b>11.2</b> Identification</a></li>
<li class="chapter" data-level="11.3" data-path="11-proofs.html"><a href="11-proofs.html#confidence-interval"><i class="fa fa-check"></i><b>11.3</b> Building a confidence interval</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-proofs.html"><a href="11-proofs.html#clt"><i class="fa fa-check"></i><b>11.3.1</b> CLT &amp; Slutsky’s lemma</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-proofs.html"><a href="11-proofs.html#order"><i class="fa fa-check"></i><b>11.3.2</b> CLT and order statistics</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-proofs.html"><a href="11-proofs.html#another-rep"><i class="fa fa-check"></i><b>11.4</b> Another representation of the parameter of interest</a></li>
<li class="chapter" data-level="11.5" data-path="11-proofs.html"><a href="11-proofs.html#prop-delta-method"><i class="fa fa-check"></i><b>11.5</b> The delta-method</a></li>
<li class="chapter" data-level="11.6" data-path="11-proofs.html"><a href="11-proofs.html#asymp-neglig-remain"><i class="fa fa-check"></i><b>11.6</b> Asymptotic negligibility of the remainder term</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-references.html"><a href="12-references.html"><i class="fa fa-check"></i><b>12</b> References</a></li>
<li class="chapter" data-level="13" data-path="13-more-proofs.html"><a href="13-more-proofs.html"><i class="fa fa-check"></i><b>13</b> More results and their proofs</a><ul>
<li class="chapter" data-level="13.1" data-path="13-more-proofs.html"><a href="13-more-proofs.html#estimation-of-the-asymptotic-variance-of-an-estimator"><i class="fa fa-check"></i><b>13.1</b> Estimation of the asymptotic variance of an estimator</a><ul>
<li class="chapter" data-level="13.1.1" data-path="13-more-proofs.html"><a href="13-more-proofs.html#iptw-est-var"><i class="fa fa-check"></i><b>13.1.1</b> IPTW estimator based on a well-specified model</a></li>
<li class="chapter" data-level="13.1.2" data-path="13-more-proofs.html"><a href="13-more-proofs.html#gcomp-est-var"><i class="fa fa-check"></i><b>13.1.2</b> G-computation estimator based on a well-specified model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-references-1.html"><a href="14-references-1.html"><i class="fa fa-check"></i><b>14</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Ride in Targeted Learning Territory</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\(\newcommand{\bbO}{\mathbb{O}}\)
\(\newcommand{\bbD}{\mathbb{D}}\)
\(\newcommand{\bbP}{\mathbb{P}}\)
\(\newcommand{\bbR}{\mathbb{R}}\)
\(\newcommand{\Algo}{\widehat{\mathcal{A}}}\)
\(\newcommand{\calF}{\mathcal{F}}\)
\(\newcommand{\calM}{\mathcal{M}}\)
\(\newcommand{\calP}{\mathcal{P}}\)
\(\newcommand{\calO}{\mathcal{O}}\)
\(\newcommand{\calQ}{\mathcal{Q}}\)
\(\newcommand{\Exp}{\textrm{E}}\)
\(\newcommand{\IC}{\textrm{IC}}\)
\(\newcommand{\Gbar}{\bar{G}}\)
\(\newcommand{\one}{\textbf{1}}\)
\(\renewcommand{\Pr}{\textrm{Pr}}\)
\(\newcommand{\Psihat}{\widehat{\Psi}}\)
\(\newcommand{\Qbar}{\bar{Q}}\)
\(\newcommand{\tcg}[1]{\textcolor{olive}{#1}}\)
\(\DeclareMathOperator{\Dirac}{Dirac}\)
\(\DeclareMathOperator{\expit}{expit}\)
\(\DeclareMathOperator{\logit}{logit}\)
\(\DeclareMathOperator{\Rem}{Rem}\)
\(\DeclareMathOperator{\Var}{Var}\)
<div id="smooth" class="section level1">
<h1><span class="header-section-number">Section 3</span> Smoothness</h1>
<div id="smooth-first-pass" class="section level2">
<h2><span class="header-section-number">3.1</span> Fluctuating smoothly</h2>
<p>Within our view of the target parameter as a statistical mapping evaluated at the law of the experiment, it is natural to inquire of properties this functional enjoys. For example, we may be interested in asking how the value of <span class="math inline">\(\Psi(P)\)</span> changes as we consider laws that <em>get nearer to</em> <span class="math inline">\(P\)</span> in <span class="math inline">\(\calM\)</span>. If small deviations from <span class="math inline">\(P_0\)</span> result in large changes in <span class="math inline">\(\Psi(P_0)\)</span>, then we might hypothesize that it will be difficult to produce stable estimators of <span class="math inline">\(\psi_0\)</span>. Fortunately, this turns out not to be the case for the mapping <span class="math inline">\(\Psi\)</span>, and so we say that <span class="math inline">\(\Psi\)</span> is a <em>smooth</em> statistical mapping.</p>
<p>To discuss how <span class="math inline">\(\Psi(P)\)</span> changes for distributions that <em>get nearer</em> to <span class="math inline">\(P\)</span> in the model, we require a more concrete notion of <em>getting-nearness</em>. The notion hinges on fluctuations (or fluctuating models).</p>
<div id="fluctuations" class="section level3">
<h3><span class="header-section-number">3.1.1</span> The <code>another_experiment</code> fluctuation</h3>
<p>In Section <a href="2-parameter.html#value-another-experiment">2.3.3</a>, we discussed the nature of the object called <code>another_experiment</code> that was created when we ran <code>example(tlrider)</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">another_experiment
<span class="co">#&gt; A law for (W,A,Y) in [0,1] x {0,1} x [0,1].</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; If the law is fully characterized, you can use method</span>
<span class="co">#&gt; &#39;sample_from&#39; to sample from it.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; If you built the law, or if you are an _oracle_, you can</span>
<span class="co">#&gt; also use methods &#39;reveal&#39; to reveal its relevant features</span>
<span class="co">#&gt; (QW, Gbar, Qbar, qY -- see &#39;?reveal&#39;), and &#39;alter&#39; to change</span>
<span class="co">#&gt; some of them.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; If all its relevant features are characterized, you can</span>
<span class="co">#&gt; use methods &#39;evaluate_psi&#39; to obtain the value of &#39;Psi&#39; at</span>
<span class="co">#&gt; this law (see &#39;?evaluate_psi&#39;) and &#39;evaluate_eic&#39; to obtain</span>
<span class="co">#&gt; the efficient influence curve of &#39;Psi&#39; at this law (see &#39;?</span>
<span class="co">#&gt; evaluate_eic&#39;).</span></code></pre></div>
<p>The message is a little misleading. Indeed, <code>another_experiment</code> is not <em>a</em> law but, rather, a <em>collection</em> of laws indexed by a real-valued parameter <code>h</code>. This oracular statement (we built the object!) is evident when one looks again at the <code>sample_from</code> feature of <code>another_experiment</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">reveal</span>(another_experiment)<span class="op">$</span>sample_from
<span class="co">#&gt; function(n, h) {</span>
<span class="co">#&gt;         ## preliminary</span>
<span class="co">#&gt;         n &lt;- R.utils::Arguments$getInteger(n, c(1, Inf))</span>
<span class="co">#&gt;         h &lt;- R.utils::Arguments$getNumeric(h)</span>
<span class="co">#&gt;         ## ## &#39;Gbar&#39; and &#39;Qbar&#39; factors</span>
<span class="co">#&gt;         Gbar &lt;- another_experiment$.Gbar</span>
<span class="co">#&gt;         Qbar &lt;- another_experiment$.Qbar</span>
<span class="co">#&gt;         ## sampling</span>
<span class="co">#&gt;         ## ## context</span>
<span class="co">#&gt;         params &lt;- formals(another_experiment$.QW)</span>
<span class="co">#&gt;         W &lt;- stats::runif(n, min = eval(params$min),</span>
<span class="co">#&gt;                    max = eval(params$max))</span>
<span class="co">#&gt;         ## ## action undertaken</span>
<span class="co">#&gt;         A &lt;- stats::rbinom(n, size = 1, prob = Gbar(W))</span>
<span class="co">#&gt;         ## ## reward</span>
<span class="co">#&gt;         params &lt;- formals(another_experiment$.qY)</span>
<span class="co">#&gt;         shape1 &lt;- eval(params$shape1)</span>
<span class="co">#&gt;         QAW &lt;- Qbar(cbind(A = A, W = W), h = h)</span>
<span class="co">#&gt;         Y &lt;- stats::rbeta(n,</span>
<span class="co">#&gt;                           shape1 = shape1,</span>
<span class="co">#&gt;                           shape2 = shape1 * (1 - QAW) / QAW)</span>
<span class="co">#&gt;         ## ## observation</span>
<span class="co">#&gt;         obs &lt;- cbind(W = W, A = A, Y = Y)</span>
<span class="co">#&gt;         return(obs)</span>
<span class="co">#&gt;       }</span>
<span class="co">#&gt; &lt;bytecode: 0xa6a2180&gt;</span>
<span class="co">#&gt; &lt;environment: 0xf61e700&gt;</span></code></pre></div>
Let us call <span class="math inline">\(\Pi_{h} \in \calM\)</span> the law encoded by <code>another_experiment</code> for a given <code>h</code> taken in <span class="math inline">\(]-1,1[\)</span>. Note that
<span class="math display">\[\begin{equation*}\calP  \equiv
\{\Pi_h : h \in ]-1,1[\}\end{equation*}\]</span>
<p>defines a collection of laws, <em>i.e.</em>, a statistical model.</p>
<p>We say that <span class="math inline">\(\calP\)</span> is a <em>submodel</em> of <span class="math inline">\(\calM\)</span> because <span class="math inline">\(\calP \subset \calM\)</span>. Moreover, we say that this submodel is <em>through <span class="math inline">\(\Pi_0\)</span></em> since <span class="math inline">\(\Pi_{h} = \Pi_{0}\)</span> when <span class="math inline">\(h = 0\)</span>. We also say that <span class="math inline">\(\calP\)</span> is a <em>fluctuation</em> of <span class="math inline">\(\Pi_{0}\)</span>.</p>
<p>One could enumerate many possible submodels in <span class="math inline">\(\calM\)</span> through <span class="math inline">\(\Pi_0\)</span>. It turns out that all that matters for our purposes is the form of the submodel in a neighborhood of <span class="math inline">\(\Pi_0\)</span>. We informally say that this local behavior describes the <em>direction</em> of a submodel through <span class="math inline">\(\Pi_0\)</span>. We formalize this notion Section <a href="3-smooth.html#smooth-second-pass">3.3</a>.</p>
<p>We now have a notion of how to move through the model space <span class="math inline">\(P \in \calM\)</span> and can study how the value of the parameter changes as we move away from a law <span class="math inline">\(P\)</span>. Above, we said that <span class="math inline">\(\Psi\)</span> is a smooth parameter if it does not change “too much” as we move towards <span class="math inline">\(P\)</span> in any particular direction. That is, we should hope that <span class="math inline">\(\Psi\)</span> is differentiable along our submodel at <span class="math inline">\(P\)</span>.</p>
<p>This idea too is formalized in Section <a href="3-smooth.html#smooth-second-pass">3.3</a>. We now turn to illustrating this idea numerically.</p>
</div>
<div id="numerical-illus" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Numerical illustration</h3>
<p>The code below evaluates how the parameter changes for laws in <span class="math inline">\(\calP\)</span>, and approximates the derivative of the parameter along the submodel <span class="math inline">\(\calP\)</span> at <span class="math inline">\(\Pi_0\)</span>. Recall that the numerical value of <span class="math inline">\(\Psi(\Pi_{0})\)</span> has already been computed and is stored in object <code>psi_Pi_zero</code>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">approx &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="fl">1e2</span>)
psi_Pi_h &lt;-<span class="st"> </span><span class="kw">sapply</span>(approx, <span class="cf">function</span>(t) {
  <span class="kw">evaluate_psi</span>(another_experiment, <span class="dt">h =</span> t)
})
slope_approx &lt;-<span class="st"> </span>(psi_Pi_h <span class="op">-</span><span class="st"> </span>psi_Pi_zero) <span class="op">/</span><span class="st"> </span>approx
slope_approx &lt;-<span class="st"> </span>slope_approx[<span class="kw">min</span>(<span class="kw">which</span>(approx <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))]
<span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> approx, <span class="dt">y =</span> psi_Pi_h), <span class="kw">aes</span>(x, y),
             <span class="dt">color =</span> <span class="st">&quot;#CC6666&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="op">-</span><span class="dv">1</span>, <span class="dt">y =</span> psi_Pi_zero <span class="op">-</span><span class="st"> </span>slope_approx,
                   <span class="dt">xend =</span> <span class="dv">1</span>, <span class="dt">yend =</span> psi_Pi_zero <span class="op">+</span><span class="st"> </span>slope_approx),
               <span class="dt">arrow =</span> <span class="kw">arrow</span>(<span class="dt">length =</span> <span class="kw">unit</span>(<span class="fl">0.03</span>, <span class="st">&quot;npc&quot;</span>)),
               <span class="dt">color =</span> <span class="st">&quot;#9999CC&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="st">&quot;#66CC99&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> psi_Pi_zero, <span class="dt">color =</span> <span class="st">&quot;#66CC99&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;h&quot;</span>, <span class="dt">y =</span> <span class="kw">expression</span>(<span class="kw">Psi</span>(Pi[h]))) </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:psi-approx-psi-one"></span>
<img src="img/psi-approx-psi-one-1.png" alt="Evolution of statistical mapping \(\Psi\) along fluctuation \(\{\Pi_{h} : h \in H\}\)." width="70%" />
<p class="caption">
Figure 3.1: Evolution of statistical mapping <span class="math inline">\(\Psi\)</span> along fluctuation <span class="math inline">\(\{\Pi_{h} : h \in H\}\)</span>.
</p>
</div>
<p>The dotted curve represents the function <span class="math inline">\(h \mapsto \Psi(\Pi_{h})\)</span>. The blue line represents the tangent to the previous curve at <span class="math inline">\(h=0\)</span>, which indeed appears to be differentiable around <span class="math inline">\(h=0\)</span>. In Section <a href="3-smooth.html#revisiting">3.4</a>, we derive a closed-form expression for the slope of the blue curve.</p>
</div>
</div>
<div id="exo-yet-another-experiment" class="section level2">
<h2><span class="header-section-number">3.2</span> ⚙ Yet another experiment</h2>
<ol style="list-style-type: decimal">
<li><p>Adapt the code from Problem 1 in Section <a href="1-a-ride.html#exo-visualization">1.3</a> to visualize <span class="math inline">\(w \mapsto \Exp_{\Pi_h}(Y | A = 1, W = w)\)</span>, <span class="math inline">\(w \mapsto \Exp_{\Pi_h}(Y | A = 0, W=w)\)</span>, and <span class="math inline">\(w \mapsto \Exp_{\Pi_h}(Y | A = 1, W=w) - \Exp_{\Pi_h}(Y | A = 0, W=w)\)</span>, for <span class="math inline">\(h \in \{-1/2, 0, 1/2\}\)</span>.</p></li>
<li><p>Run the following chunk of code.</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yet_another_experiment &lt;-<span class="st"> </span><span class="kw">copy</span>(another_experiment)
<span class="kw">alter</span>(yet_another_experiment,
      <span class="dt">Qbar =</span> <span class="cf">function</span>(AW, h){
        A &lt;-<span class="st"> </span>AW[, <span class="st">&quot;A&quot;</span>]
        W &lt;-<span class="st"> </span>AW[, <span class="st">&quot;W&quot;</span>]
        <span class="kw">expit</span>( <span class="kw">logit</span>( A <span class="op">*</span><span class="st"> </span>W <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>A) <span class="op">*</span><span class="st"> </span>W<span class="op">^</span><span class="dv">2</span> ) <span class="op">+</span><span class="st"> </span>
<span class="st">               </span>h <span class="op">*</span><span class="st"> </span>(<span class="dv">2</span><span class="op">*</span>A <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="kw">ifelse</span>(A <span class="op">==</span><span class="st"> </span><span class="dv">1</span>,
                                      <span class="kw">sin</span>((<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>W) <span class="op">*</span><span class="st"> </span>pi <span class="op">/</span><span class="st"> </span><span class="dv">6</span>), 
                                      <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sin</span>((<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>W) <span class="op">*</span><span class="st"> </span>pi <span class="op">/</span><span class="st"> </span><span class="dv">6</span>)) <span class="op">*</span>
<span class="st">               </span>(Y <span class="op">-</span><span class="st"> </span>A <span class="op">*</span><span class="st"> </span>W <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>A) <span class="op">*</span><span class="st"> </span>W<span class="op">^</span><span class="dv">2</span>))
      })</code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><p>Justify that <code>yet_another_fluctuation</code> characterizes another fluctuation of <span class="math inline">\(\Pi_{0}\)</span>. Comment upon the similarities and differences between <span class="math inline">\(\{\Pi_{h} : h \in ]-1,1[\}\)</span> and <span class="math inline">\(\{\Pi_{h}&#39; : h \in ]-1,1[\}\)</span>.</p></li>
<li><p>Repeat Problem 1 above with <span class="math inline">\(\Pi_{h}&#39;\)</span> substituted for <span class="math inline">\(\Pi_{h}\)</span>.</p></li>
<li><p>Re-produce Figure <a href="3-smooth.html#fig:psi-approx-psi-one">3.1</a> for the <span class="math inline">\(\{\Pi_h&#39; : h \in ]-1,1[\}\)</span> fluctuation. Comment on the similarities and differences between the resulting figure and Figure <a href="3-smooth.html#fig:psi-approx-psi-one">3.1</a>. In particular, how does the behavior of the target parameter around <span class="math inline">\(h = 0\)</span> compare between laws <span class="math inline">\(\Pi_0\)</span> and <span class="math inline">\(\Pi_0&#39;\)</span>?</p></li>
</ol>
</div>
<div id="smooth-second-pass" class="section level2">
<h2><span class="header-section-number">3.3</span> ☡  More on fluctuations and smoothness</h2>
<div id="fluctuations" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Fluctuations</h3>
Let us now formally define what it means for statistical mapping <span class="math inline">\(\Psi\)</span> to be smooth at every <span class="math inline">\(P \in \calM\)</span>. For every <span class="math inline">\(h \in H \equiv ]-M^{-1},M^{-1}[\)</span>, we can define a law <span class="math inline">\(P_{h} \in \calM\)</span> by setting <span class="math inline">\(P_{h} \ll P\)</span><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> and
<span class="math display" id="eq:fluct">\[\begin{equation}
\frac{dP_h}{dP} \equiv
1 + h s, \tag{3.1}
\end{equation}\]</span>
where <span class="math inline">\(s : \calO\to \bbR\)</span> is a (measurable) function of <span class="math inline">\(O\)</span> such that <span class="math inline">\(s(O)\)</span> is not equal to zero <span class="math inline">\(P\)</span>-almost surely, <span class="math inline">\(\Exp_{P} (s(O)) = 0\)</span>, and <span class="math inline">\(s\)</span> bounded by <span class="math inline">\(M\)</span>. We make the observation that
<span class="math display" id="eq:score">\[\begin{equation}
(i)  \quad P_h|_{h=0}  = P,\quad  (ii) \quad
\left.\frac{d}{dh}  \log \frac{dP_h}{dP}(O)\right|_{h=0}  =s(O).  \tag{3.2}
\end{equation}\]</span>
<p>Because of <em>(i)</em>, <span class="math inline">\(\{P_{h} : h \in H\}\)</span> is a submodel through <span class="math inline">\(P\)</span>, also referred to as a <em>fluctuation</em> of <span class="math inline">\(P\)</span>. The fluctuation is a one-dimensional submodel of <span class="math inline">\(\calM\)</span> with univariate parameter <span class="math inline">\(h \in H\)</span>. We note that <em>(ii)</em> indicates that the score of this submodel at <span class="math inline">\(h = 0\)</span> is <span class="math inline">\(s\)</span>. Thus, we say that the fluctuation is <em>in the direction</em> of <span class="math inline">\(s\)</span>.</p>
<p>Fluctuations of <span class="math inline">\(P\)</span> do not necessarily take the same form as in <a href="3-smooth.html#eq:fluct">(3.1)</a>. No matter how the fluctuation is built, for our purposes the most important feature of the fluctuation is its local shape in a neighborhood of <span class="math inline">\(P\)</span>.</p>
</div>
<div id="smoothness-and-gradients" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Smoothness and gradients</h3>
We are now prepared to provide a formal definition of smoothness of statistical mappings. We say that a statistical mapping <span class="math inline">\(\Psi\)</span> is <em>smooth</em> at every <span class="math inline">\(P \in \calM\)</span> if for each <span class="math inline">\(P \in \calM\)</span>, there exists a (measurable) function <span class="math inline">\(D^{*}(P) : \calO \to \bbR\)</span> such that <span class="math inline">\(\Exp_{P}(D^{*}(P)(O)) = 0\)</span>, <span class="math inline">\(\Var_{P}(D^{*}(P)(O)) &lt; \infty\)</span>, and, for every fluctuation <span class="math inline">\(\{P_{h} : h \in H\}\)</span> with score <span class="math inline">\(s\)</span> at <span class="math inline">\(h = 0\)</span>, the real-valued mapping <span class="math inline">\(h \mapsto \Psi(P_{h})\)</span> is differentiable at <span class="math inline">\(h=0\)</span>, with a derivative equal to
<span class="math display" id="eq:derivative">\[\begin{equation}  \Exp_{P}  \left(D^{*}(P)\tag{3.3}   (#eq:derivative)
\end{equation}\]</span>
<p>The object <span class="math inline">\(D^*(P)\)</span> in <a href="3-smooth.html#eq:derivative">(3.3)</a> is called a gradient of <span class="math inline">\(\Psi\)</span> at <span class="math inline">\(P\)</span>.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
</div>
<div id="Euclidean-perspective" class="section level3">
<h3><span class="header-section-number">3.3.3</span> A Euclidean perspective</h3>
<p>This terminology has a direct parallel to directional derivatives in the calculus of Euclidean geometry. Recall that if <span class="math inline">\(f\)</span> is a differentiable mapping from <span class="math inline">\(\bbR^p\)</span> to <span class="math inline">\(\bbR\)</span>, then the directional derivative of <span class="math inline">\(f\)</span> at <em>a point</em> <span class="math inline">\(x\)</span> (an element of <span class="math inline">\(\bbR^p\)</span>) in <em>direction</em> <span class="math inline">\(u\)</span> (a unit vector in <span class="math inline">\(\bbR^p\)</span>) is the scalar product of the gradient of <span class="math inline">\(f\)</span> and <span class="math inline">\(u\)</span>. In words, the directional derivative of <span class="math inline">\(f\)</span> at <span class="math inline">\(x\)</span> can be represented as a scalar product of the direction that we approach <span class="math inline">\(x\)</span> and the change of the function’s value at <span class="math inline">\(x\)</span>.</p>
<p>In the present problem, the law <span class="math inline">\(P\)</span> is <em>the point</em> at which we evaluate the function <span class="math inline">\(\Psi\)</span>, the score <span class="math inline">\(s\)</span> of the fluctuation is <em>the direction</em> in which we approach the point, and the gradient describes the change in the function’s value at the point.</p>
</div>
<div id="canonical-gradient" class="section level3">
<h3><span class="header-section-number">3.3.4</span> The canonical gradient</h3>
<p>In general, it is possible for many gradients to exist<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. Yet, in the special case that the model is nonparametric, only a single gradient exists. The unique gradient is then referred to as <em>the canonical gradient</em> or <em>the efficient influence curve</em>, for reasons that will be clarified in Section <a href="3-smooth.html#influence-curves">3.5</a>. In the more general setting, the canonical gradient may be defined as the minimizer of <span class="math inline">\(D\mapsto \Var_{P} (D(O))\)</span> over the set of all gradients.</p>
It is not difficult to check that the efficient influence curve of statistical mapping <span class="math inline">\(\Psi\)</span> <a href="2-parameter.html#eq:psimap">(2.6)</a> at <span class="math inline">\(P \in \calM\)</span> can be written as
<span class="math display" id="eq:eif">\[\begin{align}  D^{*}(P)  &amp;  \equiv  D_{1}^{*}   (P)  +  D_{2}^{*}  (P),  \quad
\text{where} \tag{3.4}\\  D_{1}^{*}(P) (O) &amp;\equiv \Qbar(1,W)  - \Qbar(0,W) -
\Psi(P),  \notag\\ D_{2}^{*}(P)  (O)  &amp;\equiv \frac{2A-1}{\ell\Gbar(A,W)}(Y  -
\Qbar(A,W)).\notag \end{align}\]</span>
<p>A <code>method</code> from package <code>tlrider</code> evaluates the efficient influence curve at a law described by an object of class <code>LAW</code>. It is called <code>evaluate_eic</code>. For instance, the next chunk of code evaluates the efficient influence curve <span class="math inline">\(D^{*}(P_{0})\)</span> of <span class="math inline">\(\Psi\)</span> <a href="2-parameter.html#eq:psimap">(2.6)</a> at <span class="math inline">\(P_{0} \in \calM\)</span> that is characterized by <code>experiment</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">eic_experiment &lt;-<span class="st"> </span><span class="kw">evaluate_eic</span>(experiment)</code></pre></div>
<p>The efficient influence curve <span class="math inline">\(D^{*}(P_{0})\)</span> is a function from <span class="math inline">\(\bbO\)</span> to <span class="math inline">\(\bbR\)</span>. As such, it can be evaluated at the five independent observations drawn from <span class="math inline">\(P_{0}\)</span> in Section <a href="1-a-ride.html#synthetic-experiment">1.2.2</a>. This is what the next chunk of code does:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="kw">eic_experiment</span>(five_obs))
<span class="co">#&gt; [1]  0.260  0.161 -0.387 -0.186  0.110</span></code></pre></div>
<p>Finally, the efficient influence curve can be visualized as two images that represent <span class="math inline">\((w,y) \mapsto D^{*}(P_{0})(w,a,y)\)</span> for <span class="math inline">\(a = 0,1\)</span>, respectively:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">crossing</span>(<span class="dt">w =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="fl">2e2</span>),
     <span class="dt">a =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),
     <span class="dt">y =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="fl">2e2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">eic =</span> <span class="kw">eic_experiment</span>(<span class="kw">cbind</span>(<span class="dt">Y=</span>y,<span class="dt">A=</span>a,<span class="dt">W=</span>w))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> w, <span class="dt">y =</span> y, <span class="dt">fill =</span> eic)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_raster</span>(<span class="dt">interpolate =</span> <span class="ot">TRUE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_contour</span>(<span class="kw">aes</span>(<span class="dt">z =</span> eic), <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>a, <span class="dt">nrow =</span> <span class="dv">1</span>,
             <span class="dt">labeller =</span> <span class="kw">as_labeller</span>(<span class="kw">c</span>(<span class="st">`</span><span class="dt">0</span><span class="st">`</span> =<span class="st"> &quot;a = 0&quot;</span>, <span class="st">`</span><span class="dt">1</span><span class="st">`</span> =<span class="st"> &quot;a = 1&quot;</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">fill =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(D<span class="op">^</span><span class="st">&quot;*&quot;</span>, (P[<span class="dv">0</span>])(w,a,y))))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:eic-three"></span>
<img src="img/eic-three-1.png" alt="Visualizing the efficient influence curve \(D^{*}(P_{0})\) of \(\Psi\) (2.6) at \(P_{0}\), the law described by experiment." width="80%" />
<p class="caption">
Figure 3.2: Visualizing the efficient influence curve <span class="math inline">\(D^{*}(P_{0})\)</span> of <span class="math inline">\(\Psi\)</span> <a href="2-parameter.html#eq:psimap">(2.6)</a> at <span class="math inline">\(P_{0}\)</span>, the law described by <code>experiment</code>.
</p>
</div>
</div>
</div>
<div id="revisiting" class="section level2">
<h2><span class="header-section-number">3.4</span> A fresh look at <code>another_experiment</code></h2>
<p>We can give a fresh look at Section <a href="3-smooth.html#numerical-illus">3.1.2</a> now.</p>
<div id="deriving-the-efficient-influence-curve" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Deriving the efficient influence curve</h3>
<p>It is not difficult (though cumbersome) to verify that, up to a constant, <span class="math inline">\(\{\Pi_{h} : h \in [-1,1]\}\)</span> is a fluctuation of <span class="math inline">\(\Pi_{0}\)</span> in the direction (in the sense of <a href="3-smooth.html#eq:fluct">(3.1)</a>) of</p>
<span class="math display" id="eq:sigma0">\[\begin{align}
\notag\sigma_{0}(O) \equiv - 10 \sqrt{W} A \times \beta_{0} &amp; (A,W)\\
&amp;\times\left(\log(1    -     Y)    +     \sum_{k=0}^{3}    \left(k     +    \beta_{0}
(A,W)\right)^{-1}\right)     +      \text{constant},\\     \text{where}     \;
\beta_{0}(A,W)&amp;\equiv                                                  \frac{1
-\Qbar_{\Pi_{0}}(A,W)}{\Qbar_{\Pi_{0}}(A,W)}. \tag{3.5}\end{align}\]</span>
<p>Consequently, the slope of the dotted curve in Figure <a href="3-smooth.html#fig:psi-approx-psi-one">3.1</a> is equal to</p>
<span class="math display" id="eq:slope-Pi">\[\begin{equation}
\Exp_{\Pi_{0}} (D^{*}(\Pi_{0}) (O) \sigma_{0}(O)). \tag{3.6}
\end{equation}\]</span>
<p>Since <span class="math inline">\(D^{*}(\Pi_{0})\)</span> is centered under <span class="math inline">\(\Pi_{0}\)</span>, knowing <span class="math inline">\(\sigma_{0}\)</span> up to a constant is not problematic.</p>
</div>
<div id="numerical-validation" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Numerical validation</h3>
<p>In the following code, we check the above fact numerically. When we ran <code>example(tlrider)</code>, we created a function <code>sigma0</code>. The function implements <span class="math inline">\(\sigma_{0}\)</span> defined in <a href="3-smooth.html#eq:sigma0">(3.5)</a>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sigma0
<span class="co">#&gt; function(obs, law = another_experiment) {</span>
<span class="co">#&gt;   ## preliminary</span>
<span class="co">#&gt;   Qbar &lt;- get_feature(law, &quot;Qbar&quot;, h = 0)</span>
<span class="co">#&gt;   QAW &lt;- Qbar(obs[, c(&quot;A&quot;, &quot;W&quot;)])</span>
<span class="co">#&gt;   params &lt;- formals(get_feature(law, &quot;qY&quot;, h = 0))</span>
<span class="co">#&gt;   shape1 &lt;- eval(params$shape1)</span>
<span class="co">#&gt;   ## computations</span>
<span class="co">#&gt;   betaAW &lt;- shape1 * (1 - QAW) / QAW</span>
<span class="co">#&gt;   out &lt;- log(1 - obs[, &quot;Y&quot;])</span>
<span class="co">#&gt;   for (int in 1:shape1) {</span>
<span class="co">#&gt;     out &lt;- out + 1/(int - 1 + betaAW)</span>
<span class="co">#&gt;   }</span>
<span class="co">#&gt;   out &lt;- - out * shape1 * (1 - QAW) / QAW *</span>
<span class="co">#&gt;            10 * sqrt(obs[, &quot;W&quot;]) * obs[, &quot;A&quot;]</span>
<span class="co">#&gt;   ## no need to center given how we will use it</span>
<span class="co">#&gt;   return(out)</span>
<span class="co">#&gt;  }</span></code></pre></div>
<p>The next chunk of code approximates <a href="3-smooth.html#eq:slope-Pi">(3.6)</a> pointwise and with a confidence interval of asymptotic level 95%:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">eic_another_experiment &lt;-<span class="st"> </span><span class="kw">evaluate_eic</span>(another_experiment, <span class="dt">h =</span> <span class="dv">0</span>)
obs_another_experiment &lt;-<span class="st"> </span><span class="kw">sample_from</span>(another_experiment, B, <span class="dt">h =</span> <span class="dv">0</span>)
vars &lt;-<span class="st"> </span><span class="kw">eic_another_experiment</span>(obs_another_experiment) <span class="op">*</span>
<span class="st">  </span><span class="kw">sigma0</span>(obs_another_experiment)

sd_hat &lt;-<span class="st"> </span><span class="kw">sd</span>(vars)
(slope_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(vars))
<span class="co">#&gt; [1] 1.35</span>
(slope_CI &lt;-<span class="st"> </span>slope_hat <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>sd_hat <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(B))
<span class="co">#&gt; [1] 1.33 1.36</span></code></pre></div>
<p>Equal to 1.349 (rounded to three decimal places — hereafter, all rounding will be to three decimal places as well), the first numerical approximation <code>slope_approx</code> is not too off!</p>
</div>
</div>
<div id="influence-curves" class="section level2">
<h2><span class="header-section-number">3.5</span> ☡  Asymptotic linearity and statistical efficiency</h2>
<div id="asymptotic-linearity" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Asymptotic linearity</h3>
<p>Suppose that <span class="math inline">\(O_{1}, \ldots, O_{n}\)</span> are drawn independently from <span class="math inline">\(P\in \calM\)</span>. If an estimator <span class="math inline">\(\psi_n\)</span> of <span class="math inline">\(\Psi(P)\)</span> can be written as</p>
<span class="math display">\[\begin{equation*}  \psi_n  =  \Psi(P) +  \frac{1}{n}\sum_{i=1}^n  \IC(O_i)  +
o_{P}(1/\sqrt{n})\end{equation*}\]</span>
<p>for some function <span class="math inline">\(\IC : \calO \to \bbR\)</span> such that <span class="math inline">\(\Exp_P(\IC(O)) = 0\)</span> and <span class="math inline">\(\Var_{P}(\IC(O)) &lt; \infty\)</span>, then we say that <span class="math inline">\(\psi_n\)</span> is <em>asymptotically linear</em> with <em>influence curve</em> <span class="math inline">\(\IC\)</span>. Asymptotically linear estimators are <em>weakly convergent</em>. Specifically, if <span class="math inline">\(\psi_n\)</span> is asymptotically linear with influence curve <span class="math inline">\(\IC\)</span>, then</p>
<span class="math display" id="eq:asymp-lin">\[\begin{equation}
\sqrt{n}  (\psi_n  - \Psi(P))  =  \frac{1}{\sqrt{n}}  \sum_{i=1}^n \IC(O_i)  +
o_P(1) \tag{3.7}
\end{equation}\]</span>
<p>and, by the central limit theorem (recall that <span class="math inline">\(O_{1}, \ldots, O_{n}\)</span> are independent), <span class="math inline">\(\sqrt{n} (\psi_n - \Psi(P))\)</span> converges in law to a centered Gaussian distribution with variance <span class="math inline">\(\Var_P(\IC(O))\)</span>.</p>
</div>
<div id="influence-curves-and-gradients" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Influence curves and gradients</h3>
<p>As it happens, influence curves of regular<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> estimators are intimately related to gradients. In fact, if <span class="math inline">\(\psi_n\)</span> is a regular, asymptotically linear estimator of <span class="math inline">\(\Psi(P)\)</span> with influence curve <span class="math inline">\(\IC\)</span>, then it must be true that <span class="math inline">\(\Psi\)</span> is a smooth at <span class="math inline">\(P\)</span> and that <span class="math inline">\(\IC\)</span> is a gradient of <span class="math inline">\(\Psi\)</span> at <span class="math inline">\(P\)</span>.</p>
</div>
<div id="asymptotic-efficiency" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Asymptotic efficiency</h3>
<p>Now recall that, in Section <a href="3-smooth.html#canonical-gradient">3.3.4</a>, we defined the canonical gradient as the minimizer of <span class="math inline">\(D \mapsto \Var_{P}(D(O))\)</span> over the set of all gradients. Therefore, if <span class="math inline">\(\psi_{n}\)</span> is a regular, asymptotically linear estimator of <span class="math inline">\(\Psi(P)\)</span> (built from <span class="math inline">\(n\)</span> independent observations drawn from <span class="math inline">\(P\)</span>), then the asymptotic variance of <span class="math inline">\(\sqrt{n} (\psi_{n} - \Psi(P))\)</span> cannot be smaller than the variance of the canonical gradient of <span class="math inline">\(\Psi\)</span> at <span class="math inline">\(P\)</span>, <em>i.e.</em>,</p>
<span class="math display" id="eq:CR">\[\begin{equation}
\tag{3.8}\Var_{P}(D^{*}(P)(O)). 
\end{equation}\]</span>
<p>In other words, <a href="3-smooth.html#eq:CR">(3.8)</a> is the lower bound on the asymptotic variance of <em>any</em> regular, asymptotically linear estimator of <span class="math inline">\(\Psi(P)\)</span>. This bound is referred to as the <em>Cramér-Rao bound</em>. Any regular estimator that achieves this variance bound is said to be <em>asymptotically efficient</em> at <span class="math inline">\(P\)</span>. Because the canonical gradient is the influence curve of an asymptotically efficient estimator, it is often referred to as the <em>efficient influence curve</em>.</p>
</div>
</div>
<div id="exo-cramer-rao" class="section level2">
<h2><span class="header-section-number">3.6</span> ⚙ Cramér-Rao bounds</h2>
<ol style="list-style-type: decimal">
<li>What does the following chunk do?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obs &lt;-<span class="st"> </span><span class="kw">sample_from</span>(experiment, B)
(cramer_rao_hat &lt;-<span class="st"> </span><span class="kw">var</span>(<span class="kw">eic_experiment</span>(obs)))
<span class="co">#&gt; [1] 0.287</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Same question about this one.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obs_another_experiment &lt;-<span class="st"> </span><span class="kw">sample_from</span>(another_experiment, B, <span class="dt">h =</span> <span class="dv">0</span>)
(cramer_rao_Pi_zero_hat &lt;-
<span class="st">   </span><span class="kw">var</span>(<span class="kw">eic_another_experiment</span>(obs_another_experiment)))
<span class="co">#&gt; [1] 0.098</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><p>With a large independent sample drawn from <span class="math inline">\(\Psi(P_0)\)</span> (or <span class="math inline">\(\Psi(\Pi_0)\)</span>), is it possible to construct a regular estimator <span class="math inline">\(\psi_{n}\)</span> of <span class="math inline">\(\Psi(P_0)\)</span> (or <span class="math inline">\(\Psi(\Pi_0)\)</span>) such that the asymptotic variance of <span class="math inline">\(\sqrt{n}\)</span> times <span class="math inline">\(\psi_{n}\)</span> minus its target be smaller than the Cramér-Rao bound?</p></li>
<li><p>Is it easier to estimate <span class="math inline">\(\Psi(P_{0})\)</span> or <span class="math inline">\(\Psi(\Pi_{0})\)</span> (from independent observations drawn from either law)? In what sense? (Hint: you may want to compute a ratio.)</p></li>
</ol>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>That is, <span class="math inline">\(P_{h}\)</span> is dominated by <span class="math inline">\(P\)</span>: if an event <span class="math inline">\(A\)</span> satisfies <span class="math inline">\(P(A) = 0\)</span>, then necessarily <span class="math inline">\(P_{h} (A) = 0\)</span> too.<a href="3-smooth.html#fnref4">↩</a></p></li>
<li id="fn5"><p>Interestingly, if a fluctuation <span class="math inline">\(\{P_{h} : h \in H\}\)</span> satisfies <a href="3-smooth.html#eq:score">(3.2)</a> for a direction <span class="math inline">\(s\)</span> such that <span class="math inline">\(s\neq 0\)</span>, <span class="math inline">\(\Exp_{P}(s(O)) = 0\)</span> and <span class="math inline">\(\Var_{P} (s(O)) &lt; \infty\)</span>, then <span class="math inline">\(h \mapsto \Psi(P_{h})\)</span> is still differentiable at <span class="math inline">\(h=0\)</span> with a derivative equal to <a href="3-smooth.html#eq:derivative">(3.3)</a> beyond fluctuations of the form <a href="3-smooth.html#eq:fluct">(3.1)</a>.<a href="3-smooth.html#fnref5">↩</a></p></li>
<li id="fn6"><p>This may be at first surprising given the parallel drawn in Section <a href="3-smooth.html#Euclidean-perspective">3.3.3</a> to Euclidean geometry. However, it is important to remember that the model dictates fluctuations of <span class="math inline">\(P\)</span> that are valid submodels with respect to the full model. In turn, this determines the possible directions from which we may approach <span class="math inline">\(P\)</span>. Thus, depending on the direction, <a href="3-smooth.html#eq:derivative">(3.3)</a> may hold with different choices of <span class="math inline">\(D^*\)</span>.<a href="3-smooth.html#fnref6">↩</a></p></li>
<li id="fn7"><p>We can view <span class="math inline">\(\psi_{n}\)</span> as the by product of an algorithm <span class="math inline">\(\Psihat\)</span> trained on independent observations <span class="math inline">\(O_{1}, \ldots, O_{n}\)</span> drawn from <span class="math inline">\(P\)</span>. We say that the estimator is regular at <span class="math inline">\(P\)</span> if, for any direction <span class="math inline">\(s\neq 0\)</span> such that <span class="math inline">\(\Exp_{P} (s(O)) = 0\)</span> and <span class="math inline">\(\Var_{P} (s(O)) &lt; \infty\)</span> and fluctuation <span class="math inline">\(\{P_{h} : h \in H\}\)</span> satisfying <a href="3-smooth.html#eq:score">(3.2)</a>, the estimator <span class="math inline">\(\psi_{n,1/\sqrt{n}}\)</span> of <span class="math inline">\(\Psi(P_{1/\sqrt{n}})\)</span> obtained by training <span class="math inline">\(\Psihat\)</span> on independent observations <span class="math inline">\(O_{1}\)</span>, , <span class="math inline">\(O_{n}\)</span> drawn from <span class="math inline">\(P_{1/\sqrt{n}}\)</span> is such that <span class="math inline">\(\sqrt{n} (\psi_{n,1/\sqrt{n}} - \Psi(P_{1/\sqrt{n}}))\)</span> converges in law to a limit that does not depend on <span class="math inline">\(s\)</span>.<a href="3-smooth.html#fnref7">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="2-parameter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-double-robustness.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["tlride-book.pdf"],
"toc": {
"collapse": "section",
"scroll_hightlight": true,
"toolbar": {
"position": "static"
},
"edit": null,
"download": "pdf",
"search": true,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
}
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
